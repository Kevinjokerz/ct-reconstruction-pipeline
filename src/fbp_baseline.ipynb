{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Method 1: Filtered Back-Projection (FBP)\n",
    "## Classical CT Reconstruction Baseline\n",
    "\n",
    "This notebook implements FBP as the baseline method for comparison with iterative and deep learning approaches.\n",
    "\n",
    "**Pipeline:**\n",
    "```\n",
    "Low-dose Sinogram → FBP → Reconstructed CT Image\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 1. Setup and Imports"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T00:55:42.355661Z",
     "start_time": "2025-11-18T00:55:41.646619Z"
    }
   },
   "source": [
    "    # Install required packages\n",
    "!pip install numpy h5py scikit-image scipy matplotlib pandas tqdm"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (2.1.3)\r\n",
      "Requirement already satisfied: h5py in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (3.15.1)\r\n",
      "Requirement already satisfied: scikit-image in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (0.25.2)\r\n",
      "Requirement already satisfied: scipy in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (1.16.2)\r\n",
      "Requirement already satisfied: matplotlib in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (3.10.7)\r\n",
      "Requirement already satisfied: pandas in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (2.3.3)\r\n",
      "Requirement already satisfied: tqdm in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (4.67.1)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from scikit-image) (3.5)\r\n",
      "Requirement already satisfied: pillow>=10.1 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from scikit-image) (12.0.0)\r\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from scikit-image) (2.37.0)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from scikit-image) (2025.10.16)\r\n",
      "Requirement already satisfied: packaging>=21 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from scikit-image) (25.0)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from scikit-image) (0.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from matplotlib) (4.60.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\r\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T00:55:42.363822Z",
     "start_time": "2025-11-18T00:55:42.360916Z"
    }
   },
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import iradon\n",
    "from scipy.ndimage import zoom\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 2. Configuration"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T00:55:42.378369Z",
     "start_time": "2025-11-18T00:55:42.374707Z"
    }
   },
   "source": [
    "    # ===========================\n",
    "# CONFIGURATION\n",
    "# ===========================\n",
    "\n",
    "# Data paths\n",
    "DATA_DIR = Path(\"../data/lodopab\")  # Update for Lambda Labs\n",
    "OUTPUT_DIR = Path(\"../data/results/fbp\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# FBP parameters\n",
    "FBP_CONFIG = {\n",
    "    'filter_name': 'ramp',  # Options: 'ramp', 'shepp-logan', 'cosine', 'hamming', 'hann'\n",
    "    'interpolation': 'linear',\n",
    "    'circle': True,\n",
    "    'num_test_samples': None,  # None = all samples, or set number for subset\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Data directory: {DATA_DIR}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Filter: {FBP_CONFIG['filter_name']}\")\n",
    "print(f\"  Circle constraint: {FBP_CONFIG['circle']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Data directory: ../data/lodopab\n",
      "  Output directory: ../data/results/fbp\n",
      "  Filter: ramp\n",
      "  Circle constraint: True\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 3. FBP Reconstruction Function"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T00:55:44.887155Z",
     "start_time": "2025-11-18T00:55:42.388004Z"
    }
   },
   "source": [
    "def fbp_reconstruct(sinogram, filter_name='ramp', circle=True):\n",
    "    \"\"\"\n",
    "    Filtered Back-Projection reconstruction\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sinogram : np.ndarray\n",
    "        Sinogram of shape (1000, 513) - LoDoPaB format\n",
    "    filter_name : str\n",
    "        Filter to use: 'ramp', 'shepp-logan', 'cosine', 'hamming', 'hann'\n",
    "    circle : bool\n",
    "        Whether to assume circular object\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    reconstructed : np.ndarray\n",
    "        Reconstructed CT image of shape (362, 362)\n",
    "    \"\"\"\n",
    "    # Transpose sinogram for iradon\n",
    "    # LoDoPaB: (1000, 513) = (angles, detectors)\n",
    "    # iradon expects: (detectors, angles)\n",
    "    sinogram_transposed = sinogram.T\n",
    "    \n",
    "    # Define projection angles (0 to 180 degrees, 1000 angles)\n",
    "    theta = np.linspace(0, 180, sinogram.shape[0], endpoint=False)\n",
    "    \n",
    "    # Perform FBP\n",
    "    reconstructed = iradon(\n",
    "        sinogram_transposed,\n",
    "        theta=theta,\n",
    "        filter_name=filter_name,\n",
    "        interpolation='linear',\n",
    "        circle=circle\n",
    "    )\n",
    "    \n",
    "    # Resize to match ground truth size (362x362)\n",
    "    if reconstructed.shape != (362, 362):\n",
    "        scale_y = 362 / reconstructed.shape[0]\n",
    "        scale_x = 362 / reconstructed.shape[1]\n",
    "        reconstructed = zoom(reconstructed, (scale_y, scale_x), order=1)\n",
    "    \n",
    "    return reconstructed.astype(np.float32)\n",
    "\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing FBP reconstruction...\")\n",
    "test_sinogram = np.random.randn(1000, 513).astype(np.float32)\n",
    "test_result = fbp_reconstruct(test_sinogram)\n",
    "print(f\"✓ FBP test successful! Output shape: {test_result.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing FBP reconstruction...\n",
      "✓ FBP test successful! Output shape: (362, 362)\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 4. Evaluation Metrics"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T00:55:44.894934Z",
     "start_time": "2025-11-18T00:55:44.891056Z"
    }
   },
   "source": [
    "def calculate_psnr(img1, img2, data_range=1.0):\n",
    "    \"\"\"\n",
    "    Calculate Peak Signal-to-Noise Ratio (PSNR)\n",
    "    Higher is better\n",
    "    \"\"\"\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(data_range / np.sqrt(mse))\n",
    "\n",
    "\n",
    "def calculate_ssim(img1, img2, data_range=1.0):\n",
    "    \"\"\"\n",
    "    Calculate Structural Similarity Index (SSIM)\n",
    "    Range: [-1, 1], higher is better\n",
    "    \"\"\"\n",
    "    from skimage.metrics import structural_similarity\n",
    "    return structural_similarity(img1, img2, data_range=data_range)\n",
    "\n",
    "\n",
    "def calculate_nrmse(img1, img2):\n",
    "    \"\"\"\n",
    "    Calculate Normalized Root Mean Square Error (NRMSE)\n",
    "    Lower is better\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(np.mean((img1 - img2) ** 2))\n",
    "    nrmse = rmse / (img2.max() - img2.min())\n",
    "    return nrmse\n",
    "\n",
    "\n",
    "def normalize_image(img):\n",
    "    \"\"\"Normalize image to [0, 1]\"\"\"\n",
    "    img_min = img.min()\n",
    "    img_max = img.max()\n",
    "    if img_max - img_min > 1e-8:\n",
    "        return (img - img_min) / (img_max - img_min)\n",
    "    return img\n",
    "\n",
    "\n",
    "print(\"Evaluation metrics defined:\")\n",
    "print(\"  - PSNR (Peak Signal-to-Noise Ratio)\")\n",
    "print(\"  - SSIM (Structural Similarity Index)\")\n",
    "print(\"  - NRMSE (Normalized Root Mean Square Error)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics defined:\n",
      "  - PSNR (Peak Signal-to-Noise Ratio)\n",
      "  - SSIM (Structural Similarity Index)\n",
      "  - NRMSE (Normalized Root Mean Square Error)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 5. Load Test Data"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T00:55:44.912772Z",
     "start_time": "2025-11-18T00:55:44.902393Z"
    }
   },
   "source": [
    "test_obs_files = sorted(list(DATA_DIR.glob(\"observation_test_*.hdf5\")))\n",
    "test_gt_files = sorted(list(DATA_DIR.glob(\"ground_truth_test_*.hdf5\")))\n",
    "\n",
    "print(f\"\\nFound {len(test_obs_files)} observation files\")\n",
    "print(f\"Found {len(test_gt_files)} ground truth files\")\n",
    "\n",
    "if not test_obs_files or not test_gt_files:\n",
    "    print(\"\\nERROR: No test files found!\")\n",
    "    print(\"Please check your data directory path.\")\n",
    "else:\n",
    "    # Count total samples\n",
    "    total_samples = 0\n",
    "    for f in test_obs_files:\n",
    "        with h5py.File(f, 'r') as hf:\n",
    "            total_samples += hf['data'].shape[0]\n",
    "    \n",
    "    print(f\"\\nTotal test samples: {total_samples}\")\n",
    "    \n",
    "    if FBP_CONFIG['num_test_samples']:\n",
    "        print(f\"Will process: {FBP_CONFIG['num_test_samples']} samples (subset)\")\n",
    "    else:\n",
    "        print(f\"Will process: All {total_samples} samples\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for test data in: ../data/lodopab\n",
      "\n",
      "Found 28 observation files\n",
      "Found 28 ground truth files\n",
      "\n",
      "Total test samples: 3553\n",
      "Will process: All 3553 samples\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 6. Run FBP on Test Set"
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-18T00:55:44.920537Z"
    }
   },
   "source": [
    "# Results storage\n",
    "results = {\n",
    "    'sample_id': [],\n",
    "    'psnr': [],\n",
    "    'ssim': [],\n",
    "    'nrmse': [],\n",
    "    'file_idx': [],\n",
    "    'local_idx': []\n",
    "}\n",
    "\n",
    "# Process all test samples\n",
    "sample_count = 0\n",
    "max_samples = FBP_CONFIG['num_test_samples'] if FBP_CONFIG['num_test_samples'] else float('inf')\n",
    "\n",
    "print(\"\\nRunning FBP reconstruction on test set...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for file_idx, (obs_file, gt_file) in enumerate(zip(test_obs_files, test_gt_files)):\n",
    "    \n",
    "    with h5py.File(obs_file, 'r') as f_obs, h5py.File(gt_file, 'r') as f_gt:\n",
    "        \n",
    "        num_samples_in_file = f_obs['data'].shape[0]\n",
    "        \n",
    "        # Progress bar for this file\n",
    "        pbar = tqdm(range(num_samples_in_file), desc=f\"File {file_idx+1}/{len(test_obs_files)}\")\n",
    "        \n",
    "        for local_idx in pbar:\n",
    "            if sample_count >= max_samples:\n",
    "                break\n",
    "            \n",
    "            # Load data\n",
    "            sinogram = f_obs['data'][local_idx].astype(np.float32)\n",
    "            ground_truth = f_gt['data'][local_idx].astype(np.float32)\n",
    "            \n",
    "            # FBP reconstruction\n",
    "            reconstructed = fbp_reconstruct(\n",
    "                sinogram,\n",
    "                filter_name=FBP_CONFIG['filter_name'],\n",
    "                circle=FBP_CONFIG['circle']\n",
    "            )\n",
    "            \n",
    "            # Normalize both images\n",
    "            reconstructed_norm = normalize_image(reconstructed)\n",
    "            ground_truth_norm = normalize_image(ground_truth)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            psnr = calculate_psnr(reconstructed_norm, ground_truth_norm)\n",
    "            ssim = calculate_ssim(reconstructed_norm, ground_truth_norm)\n",
    "            nrmse = calculate_nrmse(reconstructed_norm, ground_truth_norm)\n",
    "            \n",
    "            # Store results\n",
    "            results['sample_id'].append(sample_count)\n",
    "            results['psnr'].append(psnr)\n",
    "            results['ssim'].append(ssim)\n",
    "            results['nrmse'].append(nrmse)\n",
    "            results['file_idx'].append(file_idx)\n",
    "            results['local_idx'].append(local_idx)\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'PSNR': f\"{psnr:.2f}\",\n",
    "                'SSIM': f\"{ssim:.3f}\"\n",
    "            })\n",
    "            \n",
    "            sample_count += 1\n",
    "    \n",
    "    if sample_count >= max_samples:\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"✓ Processed {sample_count} samples\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running FBP reconstruction on test set...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File 1/28: 100%|██████████| 128/128 [05:42<00:00,  2.68s/it, PSNR=12.63, SSIM=0.240]\n",
      "File 2/28: 100%|██████████| 128/128 [05:31<00:00,  2.59s/it, PSNR=14.33, SSIM=0.294]\n",
      "File 3/28: 100%|██████████| 128/128 [05:28<00:00,  2.57s/it, PSNR=18.21, SSIM=0.295]\n",
      "File 4/28: 100%|██████████| 128/128 [05:32<00:00,  2.60s/it, PSNR=11.15, SSIM=0.227]\n",
      "File 5/28: 100%|██████████| 128/128 [05:30<00:00,  2.58s/it, PSNR=14.84, SSIM=0.195]\n",
      "File 6/28: 100%|██████████| 128/128 [05:36<00:00,  2.63s/it, PSNR=16.18, SSIM=0.282]\n",
      "File 7/28: 100%|██████████| 128/128 [47:25<00:00, 22.23s/it, PSNR=12.04, SSIM=0.257]   \n",
      "File 8/28: 100%|██████████| 128/128 [05:28<00:00,  2.57s/it, PSNR=12.93, SSIM=0.229]\n",
      "File 9/28: 100%|██████████| 128/128 [20:28<00:00,  9.60s/it, PSNR=13.12, SSIM=0.212]  \n",
      "File 10/28: 100%|██████████| 128/128 [35:28<00:00, 16.63s/it, PSNR=12.35, SSIM=0.268]  \n",
      "File 11/28: 100%|██████████| 128/128 [1:29:17<00:00, 41.86s/it, PSNR=14.92, SSIM=0.230]   \n",
      "File 12/28: 100%|██████████| 128/128 [1:13:32<00:00, 34.47s/it, PSNR=10.71, SSIM=0.218]  \n",
      "File 13/28: 100%|██████████| 128/128 [1:32:48<00:00, 43.50s/it, PSNR=14.84, SSIM=0.206]   \n",
      "File 14/28: 100%|██████████| 128/128 [50:24<00:00, 23.63s/it, PSNR=12.78, SSIM=0.180]   \n",
      "File 15/28: 100%|██████████| 128/128 [57:57<00:00, 27.17s/it, PSNR=15.21, SSIM=0.234]  \n",
      "File 16/28: 100%|██████████| 128/128 [1:31:07<00:00, 42.71s/it, PSNR=10.59, SSIM=0.199]   \n",
      "File 17/28: 100%|██████████| 128/128 [45:13<00:00, 21.20s/it, PSNR=14.56, SSIM=0.098]  \n",
      "File 18/28: 100%|██████████| 128/128 [1:01:00<00:00, 28.60s/it, PSNR=14.95, SSIM=0.286] \n",
      "File 19/28: 100%|██████████| 128/128 [39:22<00:00, 18.46s/it, PSNR=12.29, SSIM=0.166]  \n",
      "File 20/28: 100%|██████████| 128/128 [05:51<00:00,  2.75s/it, PSNR=16.89, SSIM=0.384]\n",
      "File 21/28: 100%|██████████| 128/128 [05:48<00:00,  2.72s/it, PSNR=13.35, SSIM=0.189]\n",
      "File 22/28: 100%|██████████| 128/128 [05:43<00:00,  2.68s/it, PSNR=11.79, SSIM=0.227]\n",
      "File 23/28:  47%|████▋     | 60/128 [02:40<03:05,  2.72s/it, PSNR=14.37, SSIM=0.205]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 7. Calculate Summary Statistics"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    # Convert to DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Calculate statistics\n",
    "summary = {\n",
    "    'method': 'FBP',\n",
    "    'filter': FBP_CONFIG['filter_name'],\n",
    "    'num_samples': len(df_results),\n",
    "    'psnr_mean': df_results['psnr'].mean(),\n",
    "    'psnr_std': df_results['psnr'].std(),\n",
    "    'psnr_min': df_results['psnr'].min(),\n",
    "    'psnr_max': df_results['psnr'].max(),\n",
    "    'ssim_mean': df_results['ssim'].mean(),\n",
    "    'ssim_std': df_results['ssim'].std(),\n",
    "    'ssim_min': df_results['ssim'].min(),\n",
    "    'ssim_max': df_results['ssim'].max(),\n",
    "    'nrmse_mean': df_results['nrmse'].mean(),\n",
    "    'nrmse_std': df_results['nrmse'].std(),\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FBP RECONSTRUCTION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Method: {summary['method']}\")\n",
    "print(f\"Filter: {summary['filter']}\")\n",
    "print(f\"Samples: {summary['num_samples']}\")\n",
    "print()\n",
    "print(f\"PSNR:  {summary['psnr_mean']:.2f} ± {summary['psnr_std']:.2f} dB\")\n",
    "print(f\"       Range: [{summary['psnr_min']:.2f}, {summary['psnr_max']:.2f}]\")\n",
    "print()\n",
    "print(f\"SSIM:  {summary['ssim_mean']:.4f} ± {summary['ssim_std']:.4f}\")\n",
    "print(f\"       Range: [{summary['ssim_min']:.4f}, {summary['ssim_max']:.4f}]\")\n",
    "print()\n",
    "print(f\"NRMSE: {summary['nrmse_mean']:.4f} ± {summary['nrmse_std']:.4f}\")\n",
    "print(\"=\"*60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 8. Save Results"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    # Save detailed results\n",
    "df_results.to_csv(OUTPUT_DIR / 'fbp_detailed_results.csv', index=False)\n",
    "print(f\"Saved detailed results to: {OUTPUT_DIR / 'fbp_detailed_results.csv'}\")\n",
    "\n",
    "# Save summary\n",
    "with open(OUTPUT_DIR / 'fbp_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"Saved summary to: {OUTPUT_DIR / 'fbp_summary.json'}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 9. Visualize Results"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    # Plot metric distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# PSNR\n",
    "axes[0].hist(df_results['psnr'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(summary['psnr_mean'], color='red', linestyle='--', linewidth=2, label=f\"Mean: {summary['psnr_mean']:.2f}\")\n",
    "axes[0].set_xlabel('PSNR (dB)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('PSNR Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# SSIM\n",
    "axes[1].hist(df_results['ssim'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].axvline(summary['ssim_mean'], color='red', linestyle='--', linewidth=2, label=f\"Mean: {summary['ssim_mean']:.4f}\")\n",
    "axes[1].set_xlabel('SSIM')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('SSIM Distribution')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# NRMSE\n",
    "axes[2].hist(df_results['nrmse'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[2].axvline(summary['nrmse_mean'], color='red', linestyle='--', linewidth=2, label=f\"Mean: {summary['nrmse_mean']:.4f}\")\n",
    "axes[2].set_xlabel('NRMSE')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('NRMSE Distribution')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'fbp_metrics_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved plot to: {OUTPUT_DIR / 'fbp_metrics_distribution.png'}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 10. Visualize Sample Reconstructions"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    # Load and reconstruct a few samples for visualization\n",
    "num_vis_samples = 6\n",
    "sample_indices = np.linspace(0, len(df_results)-1, num_vis_samples, dtype=int)\n",
    "\n",
    "fig, axes = plt.subplots(num_vis_samples, 3, figsize=(12, 4*num_vis_samples))\n",
    "\n",
    "for plot_idx, sample_idx in enumerate(sample_indices):\n",
    "    # Get file and local index\n",
    "    file_idx = df_results.iloc[sample_idx]['file_idx']\n",
    "    local_idx = df_results.iloc[sample_idx]['local_idx']\n",
    "    \n",
    "    # Load data\n",
    "    with h5py.File(test_obs_files[file_idx], 'r') as f_obs, \\\n",
    "         h5py.File(test_gt_files[file_idx], 'r') as f_gt:\n",
    "        \n",
    "        sinogram = f_obs['data'][local_idx].astype(np.float32)\n",
    "        ground_truth = f_gt['data'][local_idx].astype(np.float32)\n",
    "    \n",
    "    # Reconstruct\n",
    "    reconstructed = fbp_reconstruct(sinogram, filter_name=FBP_CONFIG['filter_name'])\n",
    "    \n",
    "    # Normalize\n",
    "    reconstructed_norm = normalize_image(reconstructed)\n",
    "    ground_truth_norm = normalize_image(ground_truth)\n",
    "    \n",
    "    # Get metrics\n",
    "    psnr = df_results.iloc[sample_idx]['psnr']\n",
    "    ssim = df_results.iloc[sample_idx]['ssim']\n",
    "    \n",
    "    # Plot sinogram\n",
    "    axes[plot_idx, 0].imshow(sinogram, cmap='gray', aspect='auto')\n",
    "    axes[plot_idx, 0].set_title(f'Sample {sample_idx}\\nSinogram')\n",
    "    axes[plot_idx, 0].set_xlabel('Detector')\n",
    "    axes[plot_idx, 0].set_ylabel('Angle')\n",
    "    \n",
    "    # Plot FBP reconstruction\n",
    "    axes[plot_idx, 1].imshow(reconstructed_norm, cmap='gray')\n",
    "    axes[plot_idx, 1].set_title(f'FBP Reconstruction\\nPSNR: {psnr:.2f} dB, SSIM: {ssim:.3f}')\n",
    "    axes[plot_idx, 1].axis('off')\n",
    "    \n",
    "    # Plot ground truth\n",
    "    axes[plot_idx, 2].imshow(ground_truth_norm, cmap='gray')\n",
    "    axes[plot_idx, 2].set_title('Ground Truth')\n",
    "    axes[plot_idx, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'fbp_sample_reconstructions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved sample reconstructions to: {OUTPUT_DIR / 'fbp_sample_reconstructions.png'}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
