{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net for CT Image Reconstruction\n",
    "## LoDoPaB Dataset - Training on Lambda Labs GPU\n",
    "\n",
    "This notebook trains a U-Net to enhance FBP reconstructions of low-dose CT images.\n",
    "\n",
    "**Pipeline:**\n",
    "```\n",
    "Sinogram → FBP → Noisy Image → U-Net → Enhanced Image\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install torch torchvision h5py scikit-image scipy tqdm matplotlib tensorboard numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from skimage.transform import iradon\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# CONFIGURATION - EDIT THESE\n",
    "# ===========================\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"../data/lodopab\")   # Update this!\n",
    "\n",
    "# Training hyperparameters\n",
    "CONFIG = {\n",
    "    'num_epochs': 50,\n",
    "    'batch_size': 16,          # Increase for GPU (Lambda Labs can handle 16-32)\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_workers': 8,          # Use multiple workers on Lambda Labs\n",
    "    'device': 'cuda',          # Use GPU\n",
    "    'pin_memory': True,        # Enable for GPU\n",
    "    'save_dir': '../data/results/checkpoints/unet',\n",
    "    'log_dir': '../data/results/logs/unet',\n",
    "    'use_all_train_files': False,  # Set True to use all training data\n",
    "    'num_train_files': 10,     # Number of training files to use (if use_all_train_files=False)\n",
    "    'num_val_files': 2,        # Number of validation files to use\n",
    "}\n",
    "\n",
    "# Loss weights\n",
    "LOSS_WEIGHTS = {\n",
    "    'mse': 1.0,\n",
    "    'ssim': 0.1,\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoDoPaBDataset(Dataset):\n",
    "    def __init__(self, obs_files, gt_files, transform=None, use_fbp=True):\n",
    "        self.obs_files = obs_files\n",
    "        self.gt_files = gt_files\n",
    "        self.transform = transform\n",
    "        self.use_fbp = use_fbp\n",
    "        \n",
    "        # Calculate total number of samples\n",
    "        self.file_offsets = [0]\n",
    "        for obs_file in obs_files:\n",
    "            with h5py.File(obs_file, 'r') as f:\n",
    "                self.file_offsets.append(self.file_offsets[-1] + f['data'].shape[0])\n",
    "        \n",
    "        self.total_samples = self.file_offsets[-1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "    \n",
    "    def _get_file_and_index(self, idx):\n",
    "        \"\"\"Convert global index to (file_index, local_index)\"\"\"\n",
    "        for i in range(len(self.file_offsets) - 1):\n",
    "            if idx < self.file_offsets[i + 1]:\n",
    "                file_idx = i\n",
    "                local_idx = idx - self.file_offsets[i]\n",
    "                return file_idx, local_idx\n",
    "        raise IndexError(f\"Index {idx} out of range\")\n",
    "    \n",
    "    def _simple_fbp(self, sinogram):\n",
    "        \"\"\"\n",
    "        FBP reconstruction using skimage\n",
    "        \n",
    "        LoDoPaB sinogram: (1000, 513) = (angles, detectors)\n",
    "        iradon expects: (detectors, angles)\n",
    "        \"\"\"\n",
    "        # Transpose: (1000, 513) → (513, 1000)\n",
    "        sinogram_transposed = sinogram.T\n",
    "        \n",
    "        # 1000 angles from 0 to 180 degrees\n",
    "        theta = np.linspace(0, 180, sinogram.shape[0], endpoint=False)\n",
    "        \n",
    "        # Perform FBP\n",
    "        reconstructed = iradon(\n",
    "            sinogram_transposed,\n",
    "            theta=theta,\n",
    "            filter_name='ramp',\n",
    "            interpolation='linear',\n",
    "            circle=False,\n",
    "            output_size= 362\n",
    "        )\n",
    "        \n",
    "        # Resize to 362×362\n",
    "        if reconstructed.shape != (362, 362):\n",
    "            scale_y = 362 / reconstructed.shape[0]\n",
    "            scale_x = 362 / reconstructed.shape[1]\n",
    "            reconstructed = zoom(reconstructed, (scale_y, scale_x), order=1)\n",
    "\n",
    "        reconstructed = np.rot90(reconstructed, k=-1)\n",
    "        return reconstructed.astype(np.float32)\n",
    "    \n",
    "    def _normalize(self, img):\n",
    "        \"\"\"Normalize image to [0, 1]\"\"\"\n",
    "        img_min = img.min()\n",
    "        img_max = img.max()\n",
    "        if img_max - img_min > 1e-8:\n",
    "            return (img - img_min) / (img_max - img_min)\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_idx, local_idx = self._get_file_and_index(idx)\n",
    "        \n",
    "        # Open files on-demand (multiprocessing-safe)\n",
    "        with h5py.File(self.obs_files[file_idx], 'r') as f_obs, \\\n",
    "             h5py.File(self.gt_files[file_idx], 'r') as f_gt:\n",
    "            \n",
    "            sinogram = f_obs['data'][local_idx].astype(np.float32)\n",
    "            ground_truth = f_gt['data'][local_idx].astype(np.float32)\n",
    "        \n",
    "        # Apply FBP reconstruction\n",
    "        if self.use_fbp:\n",
    "            input_img = self._simple_fbp(sinogram)\n",
    "        else:\n",
    "            # For testing: use ground truth with noise\n",
    "            input_img = ground_truth + np.random.normal(0, 0.05, ground_truth.shape).astype(np.float32)\n",
    "        \n",
    "        # Normalize\n",
    "        input_img = self._normalize(input_img)\n",
    "        ground_truth = self._normalize(ground_truth)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        input_img = torch.from_numpy(input_img).unsqueeze(0)  # (1, 362, 362)\n",
    "        target_img = torch.from_numpy(ground_truth).unsqueeze(0)\n",
    "        \n",
    "        return input_img, target_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. U-Net Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Double Convolution block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        \n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downsampling block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upsampling block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # Handle size mismatch\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = nn.functional.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                                     diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        # Concatenate skip connection\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"Output convolution\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net for CT Image Reconstruction\"\"\"\n",
    "    def __init__(self, n_channels=1, n_classes=1, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        # Encoder\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        \n",
    "        # Output\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        # Decoder\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        \n",
    "        # Output\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined MSE + SSIM loss\"\"\"\n",
    "    def __init__(self, mse_weight=1.0, ssim_weight=0.1):\n",
    "        super().__init__()\n",
    "        self.mse_weight = mse_weight\n",
    "        self.ssim_weight = ssim_weight\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    \n",
    "    def ssim_loss(self, pred, target):\n",
    "        \"\"\"Simplified SSIM loss\"\"\"\n",
    "        C1 = 0.01 ** 2\n",
    "        C2 = 0.03 ** 2\n",
    "        \n",
    "        mu_pred = pred.mean()\n",
    "        mu_target = target.mean()\n",
    "        \n",
    "        sigma_pred = pred.var()\n",
    "        sigma_target = target.var()\n",
    "        sigma_pred_target = ((pred - mu_pred) * (target - mu_target)).mean()\n",
    "        \n",
    "        ssim = ((2 * mu_pred * mu_target + C1) * (2 * sigma_pred_target + C2)) / \\\n",
    "               ((mu_pred ** 2 + mu_target ** 2 + C1) * (sigma_pred + sigma_target + C2))\n",
    "        \n",
    "        return 1 - ssim\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        mse = self.mse_loss(pred, target)\n",
    "        ssim = self.ssim_loss(pred, target)\n",
    "        \n",
    "        total_loss = self.mse_weight * mse + self.ssim_weight * ssim\n",
    "        \n",
    "        return total_loss, {'mse': mse.item(), 'ssim': ssim.item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_mse = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Loss\n",
    "        loss, loss_dict = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate\n",
    "        total_loss += loss.item()\n",
    "        total_mse += loss_dict['mse']\n",
    "        total_ssim += loss_dict['ssim']\n",
    "        \n",
    "        # Update progress\n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'mse': f\"{loss_dict['mse']:.4f}\"\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(dataloader), total_mse / len(dataloader), total_ssim / len(dataloader)\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_mse = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(dataloader, desc='Validation'):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss, loss_dict = criterion(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_mse += loss_dict['mse']\n",
    "            total_ssim += loss_dict['ssim']\n",
    "    \n",
    "    return total_loss / len(dataloader), total_mse / len(dataloader), total_ssim / len(dataloader)\n",
    "\n",
    "\n",
    "def save_sample_images(model, dataloader, device, save_dir, epoch):\n",
    "    \"\"\"Save sample reconstructions\"\"\"\n",
    "    model.eval()\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs, targets = next(iter(dataloader))\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Plot first 4 samples\n",
    "        fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "        for i in range(min(4, inputs.shape[0])):\n",
    "            axes[i, 0].imshow(inputs[i, 0].cpu().numpy(), cmap='gray')\n",
    "            axes[i, 0].set_title('Input (FBP)')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(outputs[i, 0].cpu().numpy(), cmap='gray')\n",
    "            axes[i, 1].set_title('Output (U-Net)')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(targets[i, 0].cpu().numpy(), cmap='gray')\n",
    "            axes[i, 2].set_title('Target (Ground Truth)')\n",
    "            axes[i, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_dir / f'epoch_{epoch:03d}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find data files\n",
    "print(f\"Looking for data in: {DATA_DIR}\")\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    print(f\"ERROR: Data directory not found: {DATA_DIR}\")\n",
    "    print(\"Please update DATA_DIR in the configuration cell!\")\n",
    "else:\n",
    "    # Get training files\n",
    "    train_obs = sorted(list(DATA_DIR.glob(\"observation_train_*.hdf5\")))\n",
    "    train_gt = sorted(list(DATA_DIR.glob(\"ground_truth_train_*.hdf5\")))\n",
    "    \n",
    "    # Get validation files\n",
    "    val_obs = sorted(list(DATA_DIR.glob(\"observation_validation_*.hdf5\")))\n",
    "    val_gt = sorted(list(DATA_DIR.glob(\"ground_truth_validation_*.hdf5\")))\n",
    "    \n",
    "    print(f\"\\nFound {len(train_obs)} training observation files\")\n",
    "    print(f\"Found {len(train_gt)} training ground truth files\")\n",
    "    print(f\"Found {len(val_obs)} validation observation files\")\n",
    "    print(f\"Found {len(val_gt)} validation ground truth files\")\n",
    "    \n",
    "    # Subset if needed\n",
    "    if not CONFIG['use_all_train_files']:\n",
    "        train_obs = train_obs[:CONFIG['num_train_files']]\n",
    "        train_gt = train_gt[:CONFIG['num_train_files']]\n",
    "        print(f\"\\nUsing {len(train_obs)} training files (subset)\")\n",
    "    \n",
    "    val_obs = val_obs[:CONFIG['num_val_files']]\n",
    "    val_gt = val_gt[:CONFIG['num_val_files']]\n",
    "    print(f\"Using {len(val_obs)} validation files\")\n",
    "    \n",
    "    if not train_obs or not train_gt or not val_obs or not val_gt:\n",
    "        print(\"\\nERROR: Missing data files!\")\n",
    "        print(\"Make sure your LoDoPaB data is in the correct directory.\")\n",
    "    else:\n",
    "        print(\"\\n✓ Data files found successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = LoDoPaBDataset(train_obs, train_gt, use_fbp=True)\n",
    "val_dataset = LoDoPaBDataset(val_obs, val_gt, use_fbp=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Create dataloaders (optimized for GPU)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"\\nBatches per epoch: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Initialize Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(CONFIG['device'] if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model\n",
    "model = UNet(n_channels=1, n_classes=1, bilinear=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = CombinedLoss(\n",
    "    mse_weight=LOSS_WEIGHTS['mse'],\n",
    "    ssim_weight=LOSS_WEIGHTS['ssim']\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Model initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "save_dir = Path(CONFIG['save_dir'])\n",
    "log_dir = Path(CONFIG['log_dir'])\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# TensorBoard\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter(log_dir / f'run_{timestamp}')\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_mse': [], 'val_mse': []}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Training\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(1, CONFIG['num_epochs'] + 1):\n",
    "    # Train\n",
    "    train_loss, train_mse, train_ssim = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, epoch\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_mse, val_ssim = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Log metrics\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer.add_scalar('MSE/train', train_mse, epoch)\n",
    "    writer.add_scalar('MSE/val', val_mse, epoch)\n",
    "    writer.add_scalar('SSIM/train', train_ssim, epoch)\n",
    "    writer.add_scalar('SSIM/val', val_ssim, epoch)\n",
    "    writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch)\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_mse'].append(train_mse)\n",
    "    history['val_mse'].append(val_mse)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nEpoch {epoch}/{CONFIG['num_epochs']}\")\n",
    "    print(f\"Train - Loss: {train_loss:.4f}, MSE: {train_mse:.4f}, SSIM: {train_ssim:.4f}\")\n",
    "    print(f\"Val   - Loss: {val_loss:.4f}, MSE: {val_mse:.4f}, SSIM: {val_ssim:.4f}\")\n",
    "    print(f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Save sample images\n",
    "    if epoch % 5 == 0:\n",
    "        save_sample_images(model, val_loader, device, save_dir / 'samples', epoch)\n",
    "        print(f\"✓ Saved sample images\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, save_dir / 'best_model.pth')\n",
    "        print(f\"✓ Saved best model (val_loss: {val_loss:.4f})\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, save_dir / f'checkpoint_epoch_{epoch:03d}.pth')\n",
    "        print(f\"✓ Saved checkpoint\")\n",
    "\n",
    "writer.close()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Completed!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Models saved to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Total loss\n",
    "ax1.plot(history['train_loss'], label='Train Loss')\n",
    "ax1.plot(history['val_loss'], label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# MSE\n",
    "ax2.plot(history['train_mse'], label='Train MSE')\n",
    "ax2.plot(history['val_mse'], label='Val MSE')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MSE')\n",
    "ax2.set_title('Training and Validation MSE')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved training history plot to: {save_dir / 'training_history.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Load Best Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(save_dir / 'best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "print(f\"Best validation loss: {checkpoint['val_loss']:.4f}\")\n",
    "\n",
    "# Test on validation set\n",
    "with torch.no_grad():\n",
    "    inputs, targets = next(iter(val_loader))\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    \n",
    "    for i in range(min(4, inputs.shape[0])):\n",
    "        # Input (FBP)\n",
    "        axes[0, i].imshow(inputs[i, 0].cpu().numpy(), cmap='gray')\n",
    "        axes[0, i].set_title(f'Sample {i+1}\\nInput (FBP)')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Output (U-Net)\n",
    "        axes[1, i].imshow(outputs[i, 0].cpu().numpy(), cmap='gray')\n",
    "        axes[1, i].set_title('Output (U-Net)')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Target (Ground Truth)\n",
    "        axes[2, i].imshow(targets[i, 0].cpu().numpy(), cmap='gray')\n",
    "        axes[2, i].set_title('Ground Truth')\n",
    "        axes[2, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'final_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSaved final results to: {save_dir / 'final_results.png'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
