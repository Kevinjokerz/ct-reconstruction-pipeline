{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Iterative Reconstruction\n",
    "## SIRT (Simultaneous Iterative Reconstruction Technique) + TV Regularization\n",
    "\n",
    "This notebook implements iterative reconstruction as an optimization-based method.\n",
    "\n",
    "**Pipeline:**\n",
    "```\n",
    "Low-dose Sinogram → SIRT + TV Regularization → Reconstructed CT Image\n",
    "```\n",
    "\n",
    "**Advantages over FBP:**\n",
    "- Better noise suppression\n",
    "- Can incorporate prior knowledge (TV regularization)\n",
    "- More robust to incomplete data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:43:52.126766Z",
     "start_time": "2025-11-18T13:43:49.034678Z"
    }
   },
   "source": [
    "# Install required packages\n",
    "!pip install numpy h5py scipy matplotlib pandas tqdm astra-toolbox scikit-image"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (2.1.3)\r\n",
      "Requirement already satisfied: h5py in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (3.15.1)\r\n",
      "Requirement already satisfied: scipy in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (1.16.2)\r\n",
      "Requirement already satisfied: matplotlib in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (3.10.7)\r\n",
      "Requirement already satisfied: pandas in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (2.3.3)\r\n",
      "Requirement already satisfied: tqdm in /Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages (4.67.1)\r\n",
      "Collecting astra-toolbox\r\n",
      "  Using cached astra-toolbox-1.8b5.tar.gz (452 kB)\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mPreparing metadata \u001B[0m\u001B[1;32m(\u001B[0m\u001B[32mpyproject.toml\u001B[0m\u001B[1;32m)\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[26 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m ./autogen.sh: line 3: aclocal: command not found\r\n",
      "  \u001B[31m   \u001B[0m Error running aclocal\r\n",
      "  \u001B[31m   \u001B[0m Traceback (most recent call last):\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\r\n",
      "  \u001B[31m   \u001B[0m     main()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\r\n",
      "  \u001B[31m   \u001B[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\r\n",
      "  \u001B[31m   \u001B[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/davidranamagar/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 149, in prepare_metadata_for_build_wheel\r\n",
      "  \u001B[31m   \u001B[0m     return hook(metadata_directory, config_settings)\r\n",
      "  \u001B[31m   \u001B[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/7s/zf_0shnj0p7_0_519wh1bqgm0000gn/T/pip-build-env-dyan89wq/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 374, in prepare_metadata_for_build_wheel\r\n",
      "  \u001B[31m   \u001B[0m     self.run_setup()\r\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/7s/zf_0shnj0p7_0_519wh1bqgm0000gn/T/pip-build-env-dyan89wq/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 512, in run_setup\r\n",
      "  \u001B[31m   \u001B[0m     super().run_setup(setup_script=setup_script)\r\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/7s/zf_0shnj0p7_0_519wh1bqgm0000gn/T/pip-build-env-dyan89wq/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 317, in run_setup\r\n",
      "  \u001B[31m   \u001B[0m     exec(code, locals())\r\n",
      "  \u001B[31m   \u001B[0m   File \"<string>\", line 80, in <module>\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/subprocess.py\", line 389, in call\r\n",
      "  \u001B[31m   \u001B[0m     with Popen(*popenargs, **kwargs) as p:\r\n",
      "  \u001B[31m   \u001B[0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/subprocess.py\", line 1026, in __init__\r\n",
      "  \u001B[31m   \u001B[0m     self._execute_child(args, executable, preexec_fn, close_fds,\r\n",
      "  \u001B[31m   \u001B[0m   File \"/opt/anaconda3/lib/python3.12/subprocess.py\", line 1955, in _execute_child\r\n",
      "  \u001B[31m   \u001B[0m     raise child_exception_type(errno_num, err_msg, err_filename)\r\n",
      "  \u001B[31m   \u001B[0m FileNotFoundError: [Errno 2] No such file or directory: './configure'\r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[?25h\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[1;31merror\u001B[0m: \u001B[1mmetadata-generation-failed\u001B[0m\r\n",
      "\r\n",
      "\u001B[31m×\u001B[0m Encountered error while generating package metadata.\r\n",
      "\u001B[31m╰─>\u001B[0m See above for output.\r\n",
      "\r\n",
      "\u001B[1;35mnote\u001B[0m: This is an issue with the package mentioned above, not pip.\r\n",
      "\u001B[1;36mhint\u001B[0m: See above for details.\r\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:43:52.145515Z",
     "start_time": "2025-11-18T13:43:52.142130Z"
    }
   },
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from scipy.ndimage import zoom\n",
    "from skimage.metrics import structural_similarity\n",
    "\n",
    "# Try to import ASTRA\n",
    "try:\n",
    "    import astra\n",
    "    ASTRA_AVAILABLE = True\n",
    "    print(\"✓ ASTRA Toolbox available\")\n",
    "except ImportError:\n",
    "    ASTRA_AVAILABLE = False\n",
    "    print(\"⚠ ASTRA Toolbox not available, using fallback implementation\")\n",
    "\n",
    "print(\"Setup complete!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ ASTRA Toolbox not available, using fallback implementation\n",
      "Setup complete!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===========================\n",
    "# CONFIGURATION\n",
    "# ===========================\n",
    "\n",
    "# Data paths\n",
    "DATA_DIR = Path(\"../data/prepared/lodopab\")  # Update for Lambda Labs\n",
    "OUTPUT_DIR = Path(\"../data/results/iterative_reconstruction\")\n",
    "IR_CONFIG = {}\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Iterative reconstruction parameters\n",
    "IR_CONFIG = {\n",
    "    'num_iterations': 50,        # SIRT iterations\n",
    "    'tv_lambda': 0.01,           # TV regularization strength\n",
    "    'tv_iterations': 10,         # TV minimization iterations\n",
    "    'num_test_samples': 100,     # Number of samples to process (None = all)\n",
    "    'use_tv': True,              # Enable TV regularization\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Data directory: {DATA_DIR}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  SIRT iterations: {IR_CONFIG['num_iterations']}\")\n",
    "print(f\"  TV regularization: {IR_CONFIG['use_tv']}\")\n",
    "if IR_CONFIG['use_tv']:\n",
    "    print(f\"  TV lambda: {IR_CONFIG['tv_lambda']}\")\n",
    "    print(f\"  TV iterations: {IR_CONFIG['tv_iterations']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forward and Back-Projection Operators"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:43:52.317066Z",
     "start_time": "2025-11-18T13:43:52.311505Z"
    }
   },
   "source": [
    "class ProjectionOperator:\n",
    "    \"\"\"\n",
    "    Forward and back projection operators for CT reconstruction\n",
    "    Uses ASTRA if available, otherwise uses skimage as fallback\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size=362, num_angles=1000, num_detectors=513):\n",
    "        self.image_size = image_size\n",
    "        self.num_angles = num_angles\n",
    "        self.num_detectors = num_detectors\n",
    "        self.angles = np.linspace(0, np.pi, num_angles, endpoint=False)\n",
    "        \n",
    "        if ASTRA_AVAILABLE:\n",
    "            self._setup_astra()\n",
    "    \n",
    "    def _setup_astra(self):\n",
    "        \"\"\"Setup ASTRA projector\"\"\"\n",
    "        # Create geometries\n",
    "        self.vol_geom = astra.create_vol_geom(self.image_size, self.image_size)\n",
    "        self.proj_geom = astra.create_proj_geom(\n",
    "            'parallel', 1.0, self.num_detectors, self.angles\n",
    "        )\n",
    "        \n",
    "        # Create projector\n",
    "        self.proj_id = astra.create_projector('cuda', self.proj_geom, self.vol_geom)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        \"\"\"\n",
    "        Forward projection: image → sinogram\n",
    "        \"\"\"\n",
    "        if ASTRA_AVAILABLE:\n",
    "            sinogram_id, sinogram = astra.create_sino(image, self.proj_id)\n",
    "            astra.data2d.delete(sinogram_id)\n",
    "            return sinogram\n",
    "        else:\n",
    "            # Fallback: use radon transform\n",
    "            from skimage.transform import radon\n",
    "            angles_deg = np.degrees(self.angles)\n",
    "            sino = radon(image, theta=angles_deg, circle=True)\n",
    "            # Resize if needed\n",
    "            if sino.shape[1] != self.num_detectors:\n",
    "                sino = zoom(sino, (1, self.num_detectors/sino.shape[1]), order=1)\n",
    "            return sino.T  # (num_angles, num_detectors)\n",
    "    \n",
    "    def backward(self, sinogram):\n",
    "        \"\"\"\n",
    "        Back projection: sinogram → image\n",
    "        \"\"\"\n",
    "        if ASTRA_AVAILABLE:\n",
    "            recon_id = astra.data2d.create('-vol', self.vol_geom)\n",
    "            sinogram_id = astra.data2d.create('-sino', self.proj_geom, sinogram)\n",
    "            \n",
    "            cfg = astra.astra_dict('BP')\n",
    "            cfg['ProjectionDataId'] = sinogram_id\n",
    "            cfg['ReconstructionDataId'] = recon_id\n",
    "            cfg['ProjectorId'] = self.proj_id\n",
    "            \n",
    "            alg_id = astra.algorithm.create(cfg)\n",
    "            astra.algorithm.run(alg_id, 1)\n",
    "            \n",
    "            recon = astra.data2d.get(recon_id)\n",
    "            \n",
    "            astra.algorithm.delete(alg_id)\n",
    "            astra.data2d.delete([recon_id, sinogram_id])\n",
    "            \n",
    "            return recon\n",
    "        else:\n",
    "            # Fallback: use iradon\n",
    "            from skimage.transform import iradon\n",
    "            angles_deg = np.degrees(self.angles)\n",
    "            recon = iradon(sinogram.T, theta=angles_deg, filter_name=None, circle=True)\n",
    "            # Resize to target size\n",
    "            if recon.shape[0] != self.image_size:\n",
    "                scale = self.image_size / recon.shape[0]\n",
    "                recon = zoom(recon, scale, order=1)\n",
    "            return recon\n",
    "\n",
    "print(\"✓ Projection operators defined\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Projection operators defined\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SIRT Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:43:52.339294Z",
     "start_time": "2025-11-18T13:43:52.335656Z"
    }
   },
   "source": [
    "def sirt_reconstruction(sinogram, proj_op, num_iterations=50, verbose=False):\n",
    "    \"\"\"\n",
    "    Simultaneous Iterative Reconstruction Technique (SIRT)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sinogram : np.ndarray\n",
    "        Measured sinogram (num_angles, num_detectors)\n",
    "    proj_op : ProjectionOperator\n",
    "        Projection operator\n",
    "    num_iterations : int\n",
    "        Number of SIRT iterations\n",
    "    verbose : bool\n",
    "        Show progress\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    recon : np.ndarray\n",
    "        Reconstructed image\n",
    "    \"\"\"\n",
    "    # Initialize with back-projection\n",
    "    recon = proj_op.backward(sinogram)\n",
    "    recon = np.maximum(recon, 0)  # Non-negativity constraint\n",
    "    \n",
    "    # Normalization factors\n",
    "    ones_image = np.ones((proj_op.image_size, proj_op.image_size), dtype=np.float32)\n",
    "    ones_sino = np.ones_like(sinogram, dtype=np.float32)\n",
    "    \n",
    "    R = proj_op.backward(ones_sino) + 1e-6  # Column normalization\n",
    "    C = proj_op.forward(ones_image) + 1e-6  # Row normalization\n",
    "    \n",
    "    # SIRT iterations\n",
    "    iterator = tqdm(range(num_iterations), desc=\"SIRT\") if verbose else range(num_iterations)\n",
    "    \n",
    "    for iteration in iterator:\n",
    "        # Forward project\n",
    "        fp = proj_op.forward(recon)\n",
    "        \n",
    "        # Calculate residual\n",
    "        residual = (sinogram - fp) / C\n",
    "        \n",
    "        # Back project residual\n",
    "        bp = proj_op.backward(residual)\n",
    "        \n",
    "        # Update\n",
    "        recon += bp / R\n",
    "        \n",
    "        # Non-negativity\n",
    "        recon = np.maximum(recon, 0)\n",
    "    \n",
    "    return recon\n",
    "\n",
    "print(\"✓ SIRT algorithm defined\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SIRT algorithm defined\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Total Variation (TV) Regularization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:43:52.397457Z",
     "start_time": "2025-11-18T13:43:52.393369Z"
    }
   },
   "source": [
    "def tv_denoise(image, lambda_tv=0.01, num_iterations=10):\n",
    "    \"\"\"\n",
    "    Total Variation denoising using gradient descent\n",
    "    \n",
    "    Minimizes: ||image - image_noisy||^2 + lambda * TV(image)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : np.ndarray\n",
    "        Input image\n",
    "    lambda_tv : float\n",
    "        Regularization strength\n",
    "    num_iterations : int\n",
    "        Number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    denoised : np.ndarray\n",
    "        Denoised image\n",
    "    \"\"\"\n",
    "    denoised = image.copy()\n",
    "    dt = 0.25  # Time step\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        # Compute gradients\n",
    "        grad_x = np.zeros_like(denoised)\n",
    "        grad_y = np.zeros_like(denoised)\n",
    "        \n",
    "        grad_x[:, :-1] = denoised[:, 1:] - denoised[:, :-1]\n",
    "        grad_y[:-1, :] = denoised[1:, :] - denoised[:-1, :]\n",
    "        \n",
    "        # TV gradient magnitude\n",
    "        grad_mag = np.sqrt(grad_x**2 + grad_y**2 + 1e-8)\n",
    "        \n",
    "        # Normalized gradients\n",
    "        grad_x_norm = grad_x / grad_mag\n",
    "        grad_y_norm = grad_y / grad_mag\n",
    "        \n",
    "        # Divergence\n",
    "        div = np.zeros_like(denoised)\n",
    "        div[:, 1:] += grad_x_norm[:, :-1]\n",
    "        div[:, :-1] -= grad_x_norm[:, :-1]\n",
    "        div[1:, :] += grad_y_norm[:-1, :]\n",
    "        div[:-1, :] -= grad_y_norm[:-1, :]\n",
    "        \n",
    "        # Update\n",
    "        denoised = denoised + dt * ((image - denoised) + lambda_tv * div)\n",
    "        denoised = np.maximum(denoised, 0)  # Non-negativity\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "print(\"✓ TV regularization defined\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TV regularization defined\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combined SIRT + TV Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:43:52.466770Z",
     "start_time": "2025-11-18T13:43:52.463611Z"
    }
   },
   "source": [
    "def sirt_tv_reconstruction(\n",
    "    sinogram,\n",
    "    num_sirt_iterations=50,\n",
    "    tv_lambda=0.01,\n",
    "    tv_iterations=10,\n",
    "    use_tv=True,\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    SIRT reconstruction with optional TV regularization\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sinogram : np.ndarray\n",
    "        Input sinogram (1000, 513) - LoDoPaB format\n",
    "    num_sirt_iterations : int\n",
    "        Number of SIRT iterations\n",
    "    tv_lambda : float\n",
    "        TV regularization strength\n",
    "    tv_iterations : int\n",
    "        TV denoising iterations\n",
    "    use_tv : bool\n",
    "        Apply TV regularization\n",
    "    verbose : bool\n",
    "        Show progress\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    recon : np.ndarray\n",
    "        Reconstructed image (362, 362)\n",
    "    \"\"\"\n",
    "    # Create projection operator\n",
    "    proj_op = ProjectionOperator(\n",
    "        image_size=362,\n",
    "        num_angles=sinogram.shape[0],\n",
    "        num_detectors=sinogram.shape[1]\n",
    "    )\n",
    "    \n",
    "    # SIRT reconstruction\n",
    "    recon = sirt_reconstruction(\n",
    "        sinogram,\n",
    "        proj_op,\n",
    "        num_iterations=num_sirt_iterations,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Apply TV denoising\n",
    "    if use_tv:\n",
    "        recon = tv_denoise(recon, lambda_tv=tv_lambda, num_iterations=tv_iterations)\n",
    "    \n",
    "    return recon.astype(np.float32)\n",
    "\n",
    "print(\"✓ SIRT+TV reconstruction defined\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SIRT+TV reconstruction defined\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:43:52.530763Z",
     "start_time": "2025-11-18T13:43:52.527345Z"
    }
   },
   "source": [
    "def calculate_psnr(img1, img2, data_range=1.0):\n",
    "    \"\"\"Calculate PSNR\"\"\"\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(data_range / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2, data_range=1.0):\n",
    "    \"\"\"Calculate SSIM\"\"\"\n",
    "    return structural_similarity(img1, img2, data_range=data_range)\n",
    "\n",
    "def calculate_nrmse(img1, img2):\n",
    "    \"\"\"Calculate NRMSE\"\"\"\n",
    "    rmse = np.sqrt(np.mean((img1 - img2) ** 2))\n",
    "    return rmse / (img2.max() - img2.min())\n",
    "\n",
    "def normalize_image(img):\n",
    "    \"\"\"Normalize to [0, 1]\"\"\"\n",
    "    img_min, img_max = img.min(), img.max()\n",
    "    if img_max - img_min > 1e-8:\n",
    "        return (img - img_min) / (img_max - img_min)\n",
    "    return img\n",
    "\n",
    "print(\"✓ Metrics defined\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Metrics defined\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:43:52.583540Z",
     "start_time": "2025-11-18T13:43:52.567360Z"
    }
   },
   "source": [
    "# Find test files\n",
    "test_obs_files = sorted(list(DATA_DIR.glob(\"observation_test_*.hdf5\")))\n",
    "test_gt_files = sorted(list(DATA_DIR.glob(\"ground_truth_test_*.hdf5\")))\n",
    "\n",
    "print(f\"Found {len(test_obs_files)} observation files\")\n",
    "print(f\"Found {len(test_gt_files)} ground truth files\")\n",
    "\n",
    "if test_obs_files and test_gt_files:\n",
    "    total_samples = sum(h5py.File(f, 'r')['data'].shape[0] for f in test_obs_files)\n",
    "    print(f\"Total test samples: {total_samples}\")\n",
    "    \n",
    "    if IR_CONFIG['num_test_samples']:\n",
    "        print(f\"Will process: {IR_CONFIG['num_test_samples']} samples\")\n",
    "    else:\n",
    "        print(f\"Will process: All samples\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 observation files\n",
      "Found 28 ground truth files\n",
      "Total test samples: 3553\n",
      "Will process: 100 samples\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run SIRT+TV on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:43:52.800701Z",
     "start_time": "2025-11-18T13:43:52.596320Z"
    }
   },
   "source": [
    "# Results storage\n",
    "results = {\n",
    "    'sample_id': [],\n",
    "    'psnr': [],\n",
    "    'ssim': [],\n",
    "    'nrmse': [],\n",
    "}\n",
    "\n",
    "sample_count = 0\n",
    "max_samples = IR_CONFIG['num_test_samples'] if IR_CONFIG['num_test_samples'] else float('inf')\n",
    "\n",
    "print(\"\\nRunning SIRT+TV reconstruction...\")\n",
    "print(\"=\"*60)\n",
    "print(\"NOTE: This will take longer than FBP (iterative optimization)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for file_idx, (obs_file, gt_file) in enumerate(zip(test_obs_files, test_gt_files)):\n",
    "    \n",
    "    with h5py.File(obs_file, 'r') as f_obs, h5py.File(gt_file, 'r') as f_gt:\n",
    "        \n",
    "        num_in_file = f_obs['data'].shape[0]\n",
    "        pbar = tqdm(range(num_in_file), desc=f\"File {file_idx+1}\")\n",
    "        \n",
    "        for local_idx in pbar:\n",
    "            if sample_count >= max_samples:\n",
    "                break\n",
    "            \n",
    "            sinogram = f_obs['data'][local_idx].astype(np.float32)\n",
    "            ground_truth = f_gt['data'][local_idx].astype(np.float32)\n",
    "            \n",
    "            # Reconstruct\n",
    "            reconstructed = sirt_tv_reconstruction(\n",
    "                sinogram,\n",
    "                num_sirt_iterations=IR_CONFIG['num_iterations'],\n",
    "                tv_lambda=IR_CONFIG['tv_lambda'],\n",
    "                tv_iterations=IR_CONFIG['tv_iterations'],\n",
    "                use_tv=IR_CONFIG['use_tv'],\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Normalize\n",
    "            recon_norm = normalize_image(reconstructed)\n",
    "            gt_norm = normalize_image(ground_truth)\n",
    "            \n",
    "            # Metrics\n",
    "            psnr = calculate_psnr(recon_norm, gt_norm)\n",
    "            ssim = calculate_ssim(recon_norm, gt_norm)\n",
    "            nrmse = calculate_nrmse(recon_norm, gt_norm)\n",
    "            \n",
    "            results['sample_id'].append(sample_count)\n",
    "            results['psnr'].append(psnr)\n",
    "            results['ssim'].append(ssim)\n",
    "            results['nrmse'].append(nrmse)\n",
    "            \n",
    "            pbar.set_postfix({'PSNR': f\"{psnr:.2f}\", 'SSIM': f\"{ssim:.3f}\"})\n",
    "            sample_count += 1\n",
    "    \n",
    "    if sample_count >= max_samples:\n",
    "        break\n",
    "\n",
    "print(f\"\\n✓ Processed {sample_count} samples\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running SIRT+TV reconstruction...\n",
      "============================================================\n",
      "NOTE: This will take longer than FBP (iterative optimization)\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 22\u001B[39m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m h5py.File(obs_file, \u001B[33m'\u001B[39m\u001B[33mr\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f_obs, h5py.File(gt_file, \u001B[33m'\u001B[39m\u001B[33mr\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f_gt:\n\u001B[32m     21\u001B[39m     num_in_file = f_obs[\u001B[33m'\u001B[39m\u001B[33mdata\u001B[39m\u001B[33m'\u001B[39m].shape[\u001B[32m0\u001B[39m]\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m     pbar = \u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnum_in_file\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mFile \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mfile_idx\u001B[49m\u001B[43m+\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     24\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m local_idx \u001B[38;5;129;01min\u001B[39;00m pbar:\n\u001B[32m     25\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m sample_count >= max_samples:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages/tqdm/notebook.py:234\u001B[39m, in \u001B[36mtqdm_notebook.__init__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    232\u001B[39m unit_scale = \u001B[32m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.unit_scale \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.unit_scale \u001B[38;5;129;01mor\u001B[39;00m \u001B[32m1\u001B[39m\n\u001B[32m    233\u001B[39m total = \u001B[38;5;28mself\u001B[39m.total * unit_scale \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.total \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.total\n\u001B[32m--> \u001B[39m\u001B[32m234\u001B[39m \u001B[38;5;28mself\u001B[39m.container = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstatus_printer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mncols\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    235\u001B[39m \u001B[38;5;28mself\u001B[39m.container.pbar = proxy(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m    236\u001B[39m \u001B[38;5;28mself\u001B[39m.displayed = \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Project/COSC /4372 Fundametals of Medical Imaging/ct-reconstruction-pipeline/.venv/lib/python3.12/site-packages/tqdm/notebook.py:108\u001B[39m, in \u001B[36mtqdm_notebook.status_printer\u001B[39m\u001B[34m(_, total, desc, ncols)\u001B[39m\n\u001B[32m     99\u001B[39m \u001B[38;5;66;03m# Fallback to text bar if there's no total\u001B[39;00m\n\u001B[32m    100\u001B[39m \u001B[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001B[39;00m\n\u001B[32m    101\u001B[39m \u001B[38;5;66;03m# if not total:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    105\u001B[39m \n\u001B[32m    106\u001B[39m \u001B[38;5;66;03m# Prepare IPython progress bar\u001B[39;00m\n\u001B[32m    107\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m IProgress \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# #187 #451 #558 #872\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m108\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(WARN_NOIPYW)\n\u001B[32m    109\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m total:\n\u001B[32m    110\u001B[39m     pbar = IProgress(\u001B[38;5;28mmin\u001B[39m=\u001B[32m0\u001B[39m, \u001B[38;5;28mmax\u001B[39m=total)\n",
      "\u001B[31mImportError\u001B[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T13:43:52.814631Z",
     "start_time": "2025-11-18T13:42:18.147953Z"
    }
   },
   "source": [
    "# Convert to DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Summary statistics\n",
    "summary = {\n",
    "    'method': 'SIRT+TV' if IR_CONFIG['use_tv'] else 'SIRT',\n",
    "    'num_iterations': IR_CONFIG['num_iterations'],\n",
    "    'tv_enabled': IR_CONFIG['use_tv'],\n",
    "    'tv_lambda': IR_CONFIG['tv_lambda'] if IR_CONFIG['use_tv'] else None,\n",
    "    'num_samples': len(df_results),\n",
    "    'psnr_mean': df_results['psnr'].mean(),\n",
    "    'psnr_std': df_results['psnr'].std(),\n",
    "    'ssim_mean': df_results['ssim'].mean(),\n",
    "    'ssim_std': df_results['ssim'].std(),\n",
    "    'nrmse_mean': df_results['nrmse'].mean(),\n",
    "    'nrmse_std': df_results['nrmse'].std(),\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Display\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ITERATIVE RECONSTRUCTION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Method: {summary['method']}\")\n",
    "print(f\"SIRT Iterations: {summary['num_iterations']}\")\n",
    "if summary['tv_enabled']:\n",
    "    print(f\"TV Lambda: {summary['tv_lambda']}\")\n",
    "print(f\"Samples: {summary['num_samples']}\")\n",
    "print()\n",
    "print(f\"PSNR:  {summary['psnr_mean']:.2f} ± {summary['psnr_std']:.2f} dB\")\n",
    "print(f\"SSIM:  {summary['ssim_mean']:.4f} ± {summary['ssim_std']:.4f}\")\n",
    "print(f\"NRMSE: {summary['nrmse_mean']:.4f} ± {summary['nrmse_std']:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save results\n",
    "df_results.to_csv(OUTPUT_DIR / 'ir_results.csv', index=False)\n",
    "with open(OUTPUT_DIR / 'ir_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Results saved to {OUTPUT_DIR}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ITERATIVE RECONSTRUCTION RESULTS\n",
      "============================================================\n",
      "Method: SIRT+TV\n",
      "SIRT Iterations: 50\n",
      "TV Lambda: 0.01\n",
      "Samples: 0\n",
      "\n",
      "PSNR:  nan ± nan dB\n",
      "SSIM:  nan ± nan\n",
      "NRMSE: nan ± nan\n",
      "============================================================\n",
      "\n",
      "✓ Results saved to results/iterative\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
