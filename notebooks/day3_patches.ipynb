{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ff3ea1",
   "metadata": {},
   "source": [
    "# Day 3 - Patch Extraaction Pipeline (128x128, stride=64)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction & Reproducibility Notes\n",
    "**Goal:** Extract 128x128 patches from normalized CT slices (Day 2 outputs), and produce a patch dataset with `patch_manifest.csv` and `patch_meta.json`.\n",
    "\n",
    "**Why This matter:**\n",
    "- Patch-level training increases sample count and reduces GPU memory.\n",
    "- Manifest/meta ensure provenance: each path know its source slice, coordinates and statistics.\n",
    "\n",
    "**Assumption from Day 2:**\n",
    "- Each slice is `float32` and normalized to [0, 1].\n",
    "- `train_manifest.csv` contains a `path` column (relative path).\n",
    "\n",
    "**Reproducibility notes:**\n",
    "- Use this notebook for exploration/debugging.\n",
    "- Later migrate logic into a script `prepare_patches.py`.\n",
    "- Keep config immutable (`frozen=True`) to prevent silent changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131bac18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Configuration\n",
    "**Purpose:** Define a single immutable configuration object for patch extraction.  \n",
    "**Expected:** Only defines the `PathConfig` dataclass, no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ecfe4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math, json, time\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PatchConfig:\n",
    "    \"\"\"\n",
    "    Configuration for grid-based patch extraction\n",
    "    \"\"\"\n",
    "    patch_size: int = 128\n",
    "    stride: int = 64\n",
    "    pad_mode: str = \"none\"      #keep 'none' for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d27de8",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Sliding Window Coordinates\n",
    "**Purpose:** Compute top-left `(row, col)` coordinates or valid sliding windows.  \n",
    "**Validation examples:**\n",
    "- 512x512 → 49 coords (7x7 grid).\n",
    "- 480x512 → 52 coords.\n",
    "- First few coords: `(0, 0), (0, 64), (0, 128)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6dad3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512x512 -> 49 coords (expected 49)\n",
      "480x512 -> 42 coords (expected 42)\n",
      "First 3 coords (A): [(0, 0), (0, 64), (0, 128)]\n"
     ]
    }
   ],
   "source": [
    "def sliding_window_coords(h: int, w: int, cfg: PathConfig):\n",
    "    \"\"\"\n",
    "    Return list of (row, col) top-left coordinates for valid patches.\n",
    "    No padding; drops incomplete pathces at the borders\n",
    "    \"\"\"\n",
    "    ps, st = cfg.patch_size, cfg.stride\n",
    "    if h < ps or w < ps:\n",
    "        return []\n",
    "    \n",
    "    n_rows = 1 + (h - ps) // st\n",
    "    n_cols = 1 + (w - ps) // st\n",
    "    rows = [r * st for r in range(n_rows)]\n",
    "    cols = [c * st for c in range(n_cols)]\n",
    "    return [(r, c) for r in rows for c in cols]\n",
    "\n",
    "#quick smoke test\n",
    "cfg = PatchConfig(patch_size=128, stride=64)\n",
    "coords_A = sliding_window_coords(512, 512, cfg)     # expected 7*7 = 49\n",
    "coords_B = sliding_window_coords(480, 512, cfg)     # expected 6*7 = 42\n",
    "print(\"512x512 ->\", len(coords_A), \"coords (expected 49)\")\n",
    "print(\"480x512 ->\", len(coords_B), \"coords (expected 42)\")\n",
    "print(\"First 3 coords (A):\", coords_A[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2cd62b",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Patch Extraction Core\n",
    "**Purpose:** Extract patches from a 2D slice using coordinates.  \n",
    "**Returns**\n",
    "- `patches`: `(N, 128, 128)`, float32\n",
    "- `coords`: list of `(row, col)`\n",
    "\n",
    "**Validation**\n",
    "Zeros 512x512 → `(49, 128, 128)` patches, min/max = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3caea633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: (49, 128, 128) expected (49, 128, 128)\n",
      "First patch min/max: 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "def extract_patches_2d(img2d: np.ndarray, cfg: PatchConfig):\n",
    "    \"\"\"\n",
    "    Extract (N, ps, ps) patches and their (row, col) coordinates from a 2D array.\n",
    "    - img2d: ndarray (H, W), float32 preferred\n",
    "    - returns: patches (N, ps, ps) float32, coords list[(row, col)]\n",
    "    \"\"\"\n",
    "    assert img2d.ndim == 2, \"img2d must be 2D\"\n",
    "    if img2d.dtype != np.float32:\n",
    "        img2d = img2d.astype(np.float32, copy=False)\n",
    "    \n",
    "    H, W = img2d.shape\n",
    "    coords = sliding_window_coords(H, W, cfg)\n",
    "    ps = cfg.patch_size\n",
    "\n",
    "    patches = np.stack([img2d[r:r+ps, c:c+ps] for (r, c) in coords], axis=0) if coords else \\\n",
    "                np.empty((0, ps, ps), dtype=np.float32)\n",
    "    \n",
    "    # Sanity checks\n",
    "    assert patches.ndim == 3, \"patches must be (N, ps, ps)\"\n",
    "    if patches.size > 0:\n",
    "        assert patches.shape[1] == ps and patches.shape[2] == ps, \"Wrong patch size\"\n",
    "        assert patches.dtype == np.float32\n",
    "\n",
    "    return patches, coords\n",
    "\n",
    "#Quick dry-run on zeros\n",
    "cfg = PatchConfig(patch_size=128, stride=64)\n",
    "imgA = np.zeros((512, 512), dtype=np.float32)\n",
    "patchesA, coordsA = extract_patches_2d(imgA, cfg)\n",
    "print(\"Extracted:\", patchesA.shape, \"expected (49, 128, 128)\")\n",
    "print(\"First patch min/max:\", patchesA[0].min(), patchesA[0].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f279c",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Synthetic Tests\n",
    "**Purpose:** Validate patching on random arrays.  \n",
    "**Why:** Ensures variability and avoids bugs where patches are identical.  \n",
    "**Expected:** `(49,128,128)` patches, different mean/std per patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4217bc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random image -> (49, 128, 128) patches\n",
      "patch[0] mean/std: 0.005805877037346363 0.9954078793525696\n",
      "patch[1] mean/std: 0.0017823539674282074 1.0042778253555298\n",
      "patch[2] mean/std: 0.0008969246409833431 1.0121972560882568\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "imgR = rng.normal(loc=0.0, scale=1.0, size=(512, 512)).astype(np.float32)\n",
    "\n",
    "cfg = PatchConfig(patch_size=128, stride=64)\n",
    "pR, cR = extract_patches_2d(imgR, cfg)\n",
    "print(\"Random image ->\", pR.shape, \"patches\")\n",
    "\n",
    "#compare a few patch stats to ensure they differ\n",
    "for i in range(3):\n",
    "    print(f\"patch[{i}] mean/std:\", float(pR[i].mean()), float(pR[i].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b564b",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Connect to Day-2 Data\n",
    "**Purpose:** Load `train_manifest.csv`, resolve relative → absolute paths, test on real slices.  \n",
    "**Expected:**\n",
    "- Paths exists (`exists? True`).\n",
    "- Real slice (e.g., 362x362) → ~16 patches per slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66b9592e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using manifest: D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\prepared\\lodopab\\train\\train_manifest.csv\n",
      "Columns: ['index', 'path', 'min', 'max'] | Num rows 10\n",
      "data_root D:\\cosc_4372\\projects\\lowdose_ct_project\\data\n",
      "                                   path                                                                       _abs_path_local\n",
      "prepared/lodopab/train/train_000000.npy D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\prepared\\lodopab\\train\\train_000000.npy\n",
      "prepared/lodopab/train/train_000001.npy D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\prepared\\lodopab\\train\\train_000001.npy\n",
      "prepared/lodopab/train/train_000002.npy D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\prepared\\lodopab\\train\\train_000002.npy\n",
      "[0] exist? True -> D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\prepared\\lodopab\\train\\train_000000.npy\n",
      "    slice=(362, 362), patches=16, first=(0, 0)\n",
      "    patch[0] min/max=0.0/0.369978129863739, dtype=float32\n",
      "[1] exist? True -> D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\prepared\\lodopab\\train\\train_000001.npy\n",
      "    slice=(362, 362), patches=16, first=(0, 0)\n",
      "    patch[0] min/max=0.0/0.2664664387702942, dtype=float32\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = r'D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\prepared\\lodopab\\train'\n",
    "\n",
    "\n",
    "# ---------- A) Locate and read manifest (RELATIVE paths) ----------\n",
    "candidates = [\"train_manifest.csv\", \"manifest.csv\"]\n",
    "manifest_path: Optional[str] = next(\n",
    "    (os.path.join(TRAIN_DIR, n) for n in candidates if os.path.exists(os.path.join(TRAIN_DIR, n))),\n",
    "    None\n",
    ")\n",
    "assert manifest_path is not None, f\"No manifest found in: {TRAIN_DIR}\"\n",
    "print(\"Using manifest:\", manifest_path)\n",
    "\n",
    "df = pd.read_csv(manifest_path)\n",
    "print(\"Columns:\", list(df.columns), \"| Num rows\", len(df))\n",
    "assert \"path\" in df.columns, \"Manifest must contain a 'path' column (relative to data_root).\"\n",
    "\n",
    "# Infer data_root: .../data/prepared/lodopab/train  → hop up to .../data\n",
    "data_root = os.path.abspath(os.path.join(TRAIN_DIR, \"..\", \"..\", \"..\"))   #hop up to ...\\data\n",
    "print(\"data_root\", data_root)\n",
    "\n",
    "def to_abs(p_rel: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert a repository-relative path (e.g., 'prepared/lodopab/train/train_000000.npy')\n",
    "    into a local absolute path using 'data/root'.\n",
    "\n",
    "    NOTE:\n",
    "    - This is ONLY for local loading/testing in the notebook.\n",
    "    - Do NOT persist absolute paths into any public CSV/JSON.\n",
    "    \"\"\"\n",
    "    p_rel_norm = os.path.normpath(p_rel)\n",
    "    return os.path.normpath(os.path.join(data_root, p_rel_norm))\n",
    "\n",
    "# ---------- B) Local-only resolution for quick sanity tests ----------\n",
    "df[\"_abs_path_local\"] = df[\"path\"].apply(to_abs)\n",
    "\n",
    "print(df[[\"path\", \"_abs_path_local\"]].head(3).to_string(index=False))\n",
    "\n",
    "# ---------- C) Quick sanity: load a couple slices and extract patches ----------\n",
    "cfg = PatchConfig(patch_size=128, stride=64)\n",
    "\n",
    "n_test = min(2, len(df))\n",
    "for i in range(n_test):\n",
    "    p_local = df.loc[i, \"_abs_path_local\"]\n",
    "    exists = os.path.exists(p_local)\n",
    "    print(f\"[{i}] exist? {exists} -> {p_local}\")\n",
    "    assert exists, f\"Local file not found: {p_local}\"\n",
    "\n",
    "    x = np.load(p_local).astype(np.float32)\n",
    "    patches, coords = extract_patches_2d(x, cfg)\n",
    "    print(f\"    slice={x.shape}, patches={patches.shape[0]}, first={coords[0] if coords else None}\")\n",
    "    if patches.size > 0:\n",
    "        print(f\"    patch[0] min/max={float(patches[0].min())}/{float(patches[0].max())}, dtype={patches.dtype}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad4ad6",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Estimation & Naming Preview\n",
    "**Purpose:** Count expected patches and preview filename scheme.  \n",
    "**Naming scheme:** `{split}_{sliceIndex:06d}_{row:03d}_{col:03d}.npy`  \n",
    "Example: `train_000123_064_192.npy`.  \n",
    "**Expected:** ~160 patches for 10 slices, plus filename previews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "872f757a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save to: D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\patches\\lodopab\\train\n",
      "Total slices: 10\n",
      "Estimated total patches: 160\n",
      "Example filenames:\n",
      "  D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\patches\\lodopab\\train\\train_000000_000_000.npy\n",
      "  D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\patches\\lodopab\\train\\train_000000_000_064.npy\n",
      "  D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\patches\\lodopab\\train\\train_000001_000_000.npy\n",
      "  D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\patches\\lodopab\\train\\train_000001_000_064.npy\n"
     ]
    }
   ],
   "source": [
    "PATCH_ROOT = Path(r\"D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\patches\\lodopab\\train\")\n",
    "PATCH_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cfg = PatchConfig(patch_size=128, stride=64)\n",
    "\n",
    "total_patches = 0\n",
    "example_names = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    p = df.loc[i, \"_abs_path_local\"]\n",
    "    x = np.load(p).astype(np.float32)\n",
    "    patches, coords = extract_patches_2d(x, cfg)\n",
    "    total_patches += len(patches)\n",
    "\n",
    "    # preview first 2 filenames per slice (just strings; we don't save here)\n",
    "    for j, (r, c) in enumerate(coords[:2]):\n",
    "        patch_id = f\"train_{i:06d}_{r:03d}_{c:03d}\"\n",
    "        fname = PATCH_ROOT / f\"{patch_id}.npy\"\n",
    "        if len(example_names) < 4:\n",
    "            example_names.append(str(fname))\n",
    "\n",
    "\n",
    "print(\"Will save to:\", PATCH_ROOT)\n",
    "print(\"Total slices:\", len(df))\n",
    "print(\"Estimated total patches:\", total_patches)\n",
    "print(\"Example filenames:\")\n",
    "for s in example_names:\n",
    "    print(\" \", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf92401",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Save Patches + Build Manifest/Meta\n",
    "**Purpose:** Save all patches to disk, build manifest and meta for provenance.  \n",
    "\n",
    "**Manifest fields:**\n",
    "- patch_id, slice_index, src_path, row, col, patch_path\n",
    "- min, max, mean, std, dtype  \n",
    "\n",
    "**Meta fields:**\n",
    "- num_slices, num_num_patches, patch_size, strid, source_manifest, created  \n",
    "\n",
    "**Expeced:** ~160 `.npy` files, plus `patch_manifest.csv` and `patch_meta.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2ee11ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save 160 patches to D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\patches\\lodopab\\train in 0.07s\n",
      "Wrote manifest: D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\patches\\lodopab\\train\\patch_manifest.csv\n",
      "Wrote meta.json\n"
     ]
    }
   ],
   "source": [
    "PATCH_ROOT = Path(r\"D:\\cosc_4372\\projects\\lowdose_ct_project\\data\\patches\\lodopab\\train\")\n",
    "PATCH_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "manifest_rows = []\n",
    "start = time.time()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # Local load using absolute path (NOT saved to CSV)\n",
    "    src_abs = df.loc[i, \"_abs_path_local\"]\n",
    "    x = np.load(src_abs).astype(np.float32)\n",
    "\n",
    "    patches, coords = extract_patches_2d(x, cfg)\n",
    "\n",
    "    for (patch_arr, (r, c)) in zip(patches, coords):\n",
    "        patch_id = f\"train_{i:06d}_{r:03d}_{c:03d}\"\n",
    "\n",
    "        # Absolute path for local write\n",
    "        patch_abs = PATCH_ROOT / f\"{patch_id}.npy\"\n",
    "        np.save(patch_abs, patch_arr)\n",
    "\n",
    "        # ---- Save RELATIVE paths in manifest \n",
    "        src_rel = os.path.relpath(src_abs, data_root)\n",
    "        patch_rel = os.path.relpath(patch_abs, data_root)\n",
    "\n",
    "        manifest_rows.append({\n",
    "            \"patch_id\": patch_id,\n",
    "            \"slice_index\": i,\n",
    "            \"src_path\": src_rel,\n",
    "            \"row\": r,\n",
    "            \"col\": c,\n",
    "            \"patch_path\": str(patch_rel),\n",
    "            \"min\": float(patch_arr.min()),\n",
    "            \"max\": float(patch_arr.max()),\n",
    "            \"mean\": float(patch_arr.mean()),\n",
    "            \"std\": float(patch_arr.std()),\n",
    "            \"dtype\": str(patch_arr.dtype)\n",
    "        })\n",
    "    \n",
    "print(f\"Save {len(manifest_rows)} patches to {PATCH_ROOT} in {time.time()-start:.2f}s\")\n",
    "\n",
    "# Save manifest (CSV) - contains RELATIVE paths only\n",
    "manifest_csv = PATCH_ROOT / \"patch_manifest.csv\"\n",
    "pd.DataFrame(manifest_rows).to_csv(manifest_csv, index=False)\n",
    "print(\"Wrote manifest:\", manifest_csv)\n",
    "\n",
    "# Save meta.json - keep relative pointers for portability\n",
    "source_manifest_rel = os.path.relpath(manifest_path, data_root)\n",
    "path_dir_rel = os.path.relpath(PATCH_ROOT, data_root)\n",
    "\n",
    "meta = {\n",
    "    \"num_slices\": int(len(df)),\n",
    "    \"num_patches\": int(len(manifest_rows)),\n",
    "    \"patch_size\": cfg.patch_size,\n",
    "    \"stride\": cfg.stride,\n",
    "    \"source_manifest\": source_manifest_rel,\n",
    "    \"patch_dir\": path_dir_rel,\n",
    "    \"created\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "}\n",
    "with open(PATCH_ROOT / \"patch_meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Wrote meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85ccb8",
   "metadata": {},
   "source": [
    "--- \n",
    "## 9. Unit tests  \n",
    "**Purpose:** Validate patch dataset integrity.\n",
    "**Checks:**\n",
    "- Counts match between manifest and meta.  \n",
    "- Dtype = float32.  \n",
    "- Values ∈ [0, 1].\n",
    "- Shapes = (128,128).  \n",
    "\n",
    "**Expected:** Output \"Unit Tests passed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "480fd3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest rows: 160\n",
      "Meta summary: {'num_slices': 10, 'num_patches': 160, 'patch_size': 128, 'stride': 64, 'source_manifest': 'prepared\\\\lodopab\\\\train\\\\train_manifest.csv', 'patch_dir': 'patches\\\\lodopab\\\\train', 'created': '2025-10-03 23:43:24'}\n",
      "Check train_000006_128_064 -> shape=(128, 128), min=0.0000, max=0.2908\n",
      "Check train_000006_192_000 -> shape=(128, 128), min=0.0000, max=0.3913\n",
      "Check train_000008_192_064 -> shape=(128, 128), min=0.0000, max=0.3979\n",
      "Unit tests passed: shapes, dtype, range all valid\n"
     ]
    }
   ],
   "source": [
    "patch_manifest = PATCH_ROOT / \"patch_manifest.csv\"\n",
    "patch_meta = PATCH_ROOT / \"patch_meta.json\"\n",
    "\n",
    "df_p = pd.read_csv(patch_manifest)\n",
    "with open(patch_meta, \"r\") as f:\n",
    "    meta_p = json.load(f)\n",
    "\n",
    "print(\"Manifest rows:\", len(df_p))\n",
    "print(\"Meta summary:\", meta_p)\n",
    "\n",
    "# --- Test ---\n",
    "# 1) Count check\n",
    "assert len(df_p) == meta_p[\"num_patches\"], \"Mismatch: manifest vs meta.json count\"\n",
    "\n",
    "# 2) Dtype check\n",
    "assert df_p[\"dtype\"].nunique() == 1 and df_p[\"dtype\"].iloc[0] == \"float32\", \"All patches must be float32\"\n",
    "\n",
    "# 3) Range check\n",
    "assert (df_p[\"min\"] >= 0).all(), \"Patch min below 0!\"\n",
    "assert (df_p[\"max\"] <= 1).all(), \"Patch max above 1!\"\n",
    "\n",
    "# 4) Patch schema sanity\n",
    "assert df_p[\"patch_path\"].str.contains(r\"^[^:\\\\/].+\").all(), \"patch_path should be RELATIVE\"\n",
    "assert df_p[\"src_path\"].str.contains(r\"^[^:\\\\/].+\").all(), \"src_path should be RELATIVE\"\n",
    "\n",
    "# 5) Shape check on a few random samples (resolve to ABS using data_root)\n",
    "shape_ok = True\n",
    "\n",
    "# Randomly load 3 patches and check shape\n",
    "sample_rows = df_p.sample(n=min(3, len(df_p)), random_state=42)\n",
    "for _, row in sample_rows.iterrows():\n",
    "    patch_abs = os.path.normpath(os.path.join(data_root, row[\"patch_path\"]))\n",
    "    x = np.load(patch_abs)\n",
    "    if x.shape != (meta_p[\"patch_size\"], meta_p[\"patch_size\"]):\n",
    "        shape_ok=False\n",
    "    print(f\"Check {row['patch_id']} -> shape={x.shape}, min={x.min():.4f}, max={x.max():.4f}\")\n",
    "\n",
    "assert shape_ok, \"Some patch shapes not correct\"\n",
    "print(\"Unit tests passed: shapes, dtype, range all valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba42e98",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Conclusion & Next Steps  \n",
    "**Day 3 results:**\n",
    "- Patch extraction pipeline implemented (valid crops, 128x128, stride 64).\n",
    "- Train split processed with manifest/meta.\n",
    "- Unit tests confirm reproducibility.  \n",
    "\n",
    "**Next steps:**\n",
    "- Repeat for val/test splits.\n",
    "- Package into `prepare_patches.py` CLI script.\n",
    "- Optional: add patch filtering (e.g., remove low-variance patches).\n",
    "\n",
    "---  \n",
    "\n",
    "## 11. Re-run instructions\n",
    "- Prereqs: Python 3.10+, NumPy, Pandas; Day-2 outputs ready.\n",
    "- Run notebook top to bottom.\n",
    "- Change only `PathConfig` in Cell 2.\n",
    "- Expected runtime: seconds for 10 slices; lineaer scaling with dataset size.\n",
    "\n",
    "---  \n",
    "\n",
    "## 12. Common Pitfalls\n",
    "- **Path not found:** resolve relative → absolute.\n",
    "- **Values outside [0, 1]:** check Day-2 normalization.\n",
    "- **Wrong patch count:** verify image size, patch_size, stride."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lowdose_ct)",
   "language": "python",
   "name": "lowdose_ct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
